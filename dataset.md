# Heterogeneous-Multi-Modal-FL-Datasets

This repo includes four real-world multi-modal datasets collected under federated learning settings, which are used in the MobiSys 2023 paper: "Harmony: Heterogeneous Multi-Modal Federated Learning through Disentangled Model Training".

The first dataset is a multi-modal dataset for Alzheimer's Disease monitoring collected by ourselves and first appeared in the paper. The other three are public datasets pre-processed by us to federated learning settings.


# Download

  The four pre-processed datasets can be downloaded in the [onedrive folder](https://mycuhk-my.sharepoint.com/personal/1155136315_link_cuhk_edu_hk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2F1155136315%5Flink%5Fcuhk%5Fedu%5Fhk%2FDocuments%2FResearch%2FHarmony%2DDataset&ga=1). Please refer to the following discriptions of collecting and pre-processing for each dataset. 
  
  
### HARBox Dataset: Daily Activities Recognition using Smartphones


### FLASH Dataset: Human Movement Detection using Ultra Wide Band Modules


### MHAD Dataset: Walking Activity Recognition using Inertial Measurement Unit Modules


### USD Dataset: Gesture Recognition using Depth Camera



